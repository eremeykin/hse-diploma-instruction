Алгоритмы кластеризации (краткое описание)
Алгоритм A-Ward 


Алгоритм A-Ward является усовершенствованием  широко известного алгоритма иерархической агломеративной кластеризации Уорда (
Ward). Этот алгоритм основан на пошаговом объединении двух ближайших кластеров. На первом шаге все кластеры 
 состоят из единственного объекта каждый. Остановка алгоритма происходит при достижении числа кластеров, заданного пользователем , или объединении всех объектов в едином универсальном кластере. 
Степень близости между двумя кластерами вычисляется как произведение квадрата Евклидовского расстояния между центрами кластеров и произведения численностей этих кластеров, деленного на их суммарную численность. 

Недостаток алгоритма Уорда - медленность вычислений, связанная с необходимостью отыскания минимума расстояний, которых очень много на начальных этапах агломерации. В алгоритме А-Уорд эти шаги пропускаются, поскольку шаги агломерации применяются к некоторому предварительному разбиению 
объектов на достаточно малое число кластеров. Это-то предварительное разбиение используется как начальное для работы методаУорда. Классы предварительного разбиения - это кластеры, полученные методом аномальной кластеризации. 

Метод аномальной кластеризации находит и удаляет аномальные кластеры по одному до тех пор, пока не останется объектов для кластеризации. В основе этого метода лежит 
критерий квадратичной ошибки метода к-средних. Аномальным называется такой кластер, который наиболее удалён от начала координат, куда предварительно переносится
центр данных. Его построение начинается с самого удаленного объекта, а затем в него добавляются все объекты, которые ближе к центру кластера, чем к точке начала отсчета. Центр аномального кластера обновляется на каждом шаге, в то время как центр данных 
остаётся неизменным.

 Алгоритм A-Ward_pb
В - это дополнительная модификация для приложений, в которых требуется анализировать зашумленные данные, включающие нерелевантные признаки. 
В этом случае и Ward, и A-Ward плохо работают. Снизить влияние нерелевантных 
признаков позволяет введение весовых коэффициентов. В процессе работы алгоритма A-Ward_pb
В для каждого признака 
вычисляется вес, обратно пропорциональный его разбросу  внутри кластера. При этом используется не обязательно Евклидово расстояние, а метрика Минковского произвольной степени. Параметры p и В (beta) являются степенями Минковского и 
весовых коэффициентов признаков соответственно.
 
Как и в случае с A-Ward, алгоритм A-Ward_pb использует аномальную кластеризацию для предварительной 
"разведки" структуры данных и снижения времени работы, однако в алгоритме A-Ward_pb аномальная 
кластеризация обобщена с учётом дополнительных параметров.
 



Алгоритм BiKM-R
	(
Алгоритм bisecting k-means randomized 
/Раздвоение по методу k-средних) относится к классу дивизивных алгоритмов иерархического кластер-анализа. 
В отличие от агломеративных алгоритмов, где вычисления организованы "снизу-вверх" путем объединения, здесь вычисления организованы "сверху-вниз" путем разделения кластеров, начиная с универсального кластера, состоящего из всех объектов. На каждом шаге определенный кластер S разбивается на два по критерию  суммы квадратов ошибок. Для инициализации алгоритма требуется указать  
начальные центры $c_1$ и $c_2$. Затем осуществляются двух-шаговые итерации по методу к-средних при к=2. На первом шаге обновляются кластеры, путем разделения объектов на тех, что ближе к $c_{1}$ ( кластер $ S_1 $ ) и тех, что ближе к $c_{2}$ (кластер $ S_2$). На втором шаге вычисляются новые центры $ S_1 $ и $ S_2 $. Процесс заканчивается, как только новые центры совпадают со старыми. Как и в случае с
 агломеративным алгоритмом, выбор $c_1$ и $c_2$ может быть организован с использованием метода аномальных кластеров. Для инициализации алгоритма раздвоения 
используются центры двух наибольших аномальных кластеров. 


Для остановки алгоритма BiKM_R используется критерий, основанный на проецировании точек 
кластеров на случайные направления. Пусть на некотором этапе работы алгоритма имеется K кластеров. Генерируются s случайных векторов $p_i$, $i=1,...,s$. Для генерации используется нормальное 
сферическое распределение со средним в начале координат и $\sigma^2=1/V$, где $V$ – количество признаков. 
Затем каждый элемент $x$ каждого кластера $S_k$ ($k=1,..., K$) проецируется на направления $p_i$, 
координаты проекции определяются как скалярное произведение: 
$x_i=<x,p_{i}>$. Для каждого направления 
вычисляется функция плотности 
$f_k^i$ по методу ядерной оценки (окно Парзена). Если для некоторого кластера $S_k$ отношение

$\epsilon_k$ числа направлений, для которых функции плотности  $f_k^i$ имеют по крайне мере один минимум, к 
общему числу направлений меньше заданного пользователем порога $\epsilon$ , то кластер $S_k$ не 
разбивается. Для разделения выбирается в первую очередь кластер с наибольшим отношением 
$\epsilon_k / \epsilon$. Выбранный кластер разбивается но наиболее глубокому минимуму функции плотности.  





Алгоритм dePDDP (Principal Direction Divisive Partitioning) относится к иерархическим дивизивным. Первоначально критерий разделения кластера на две 
части был относительно простым: предлагалось разделить кластер по его главной компоненте на положительную 
и отрицательную части. В алгоритме dePDDP эта идея усовершенствована при помощи правила, учитывающего 
распределение данных. Разбиение производится по наиболее глубокому минимуму функции 
плотности данных, спроецированных на первую главную компоненту данного кластера. Это правило используется для решения двух сопряженных проблем: выбора кластера для разбиения и 
остановки алгоритма. Для разбиения выбирается кластер с наименьшим минимумом среди всех терминальных 
кластеров. Если кластер имеет монотонную или выпуклую функцию плотности, то такой кластер не может 
быть разделен по критерию данного алгоритма. Экспериментально было показано, что алгоритм, работающий 
на описанных принципах эффективно решает задачу кластеризации как на реальных данных, так и на 
синтетических. 
Оценка функции плотности осуществляется по методу ядерной оценки (окно Парзена).
